{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pds\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/Users/peirui/code/striatum-microcircuit/striatum-microcircuit/Fig2/output/'\n",
    "start_time = 1\n",
    "end_time = 3\n",
    "msn_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(parms_set,output_dir):\n",
    "    '''\n",
    "    load pickle data and organize into dict\n",
    "    parms_set: different types of parameters sets \n",
    "    Control;PD;PD_GluInh';Ctl_Glu\n",
    "    '''\n",
    "    data_dict_spk = {'ts_d1': [], 'ts_d2': []}\n",
    "    data_dict_lfp = {\n",
    "        'd1_times': [], 'd1_g_ex': [], 'd1_g_in': [], 'd1_V_m': [],\n",
    "        'd2_times': [], 'd2_g_ex': [], 'd2_g_in': [], 'd2_V_m': []\n",
    "    }\n",
    "    # select and sort the q value (1 simulation length 21)\n",
    "    sorted_filenames = []\n",
    "\n",
    "    for filename in os.listdir(output_dir):\n",
    "        char = filename.split('_')\n",
    "        if char[1] == 'Control':\n",
    "            sorted_filenames.append((char[4], filename))\n",
    "    sorted_filenames.sort()\n",
    "    sorted_filenames = [filename for _, filename in sorted_filenames]\n",
    "\n",
    "    for sort_file in sorted_filenames:\n",
    "        char = sort_file.split('_')\n",
    "        category, subtype = char[0], char[3]\n",
    "        filepath = os.path.join(output_dir, sort_file)\n",
    "\n",
    "        # Load the pickle file\n",
    "        with open(filepath, \"rb\") as file:\n",
    "            evs = pickle.load(file)\n",
    "\n",
    "        # Process 'spk' data\n",
    "        if category == 'spk' and subtype in ['d1', 'd2']:\n",
    "            ts = evs['events']['times']\n",
    "            data_dict_spk[f'ts_{subtype}'].append(ts)\n",
    "\n",
    "        # Process 'lfp' data\n",
    "        if category == 'lfp' and subtype in ['d1', 'd2']:\n",
    "            for key in ['times', 'g_ex', 'g_in', 'V_m']:\n",
    "                data_dict_lfp[f'{subtype}_{key}'].append(evs[key])\n",
    "    return data_dict_spk,data_dict_lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proecess_data_spk_firing(data_dict_spk,start_time,end_time,msn_size):\n",
    " '''\n",
    " Calculate the mean firing rate of D1 and D2 MSNs.\n",
    "    \n",
    "  Parameters:\n",
    "  data_dict_spk (dict): Dictionary containing spike times for D1 and D2 neurons.\n",
    "  start_time (float): Start time in seconds for calculating the firing rate.\n",
    "  end_time (float): End time in seconds for calculating the firing rate.\n",
    "  msn_size (int): Number of neurons in each population (D1 or D2).\n",
    "  \n",
    "  Returns:\n",
    "  tuple: Two lists containing the mean firing rates for D1 and D2 neurons.\n",
    " '''\n",
    " \n",
    " # Calculate the mean firing rate of D1,D2 MSN\n",
    " d1_firing=[]\n",
    " d2_firing=[]\n",
    "\n",
    " duration_secs = float(end_time - start_time)\n",
    " start_ms = start_time * 1000\n",
    " end_ms = end_time * 1000\n",
    " for key, spike_times in data_dict_spk.items():\n",
    "    \n",
    "    spikes_in_window = [np.sum((spk_times > start_ms) & (spk_times < end_ms)) for spk_times in spike_times]\n",
    "    firing_rate = [spk_in_window/ duration_secs / float(msn_size) for spk_in_window in spikes_in_window]\n",
    "\n",
    "    if key.split('_')[1] == 'd1':\n",
    "        d1_firing.append(firing_rate)\n",
    "    elif key.split('_')[1] == 'd2':\n",
    "        d2_firing.append(firing_rate)\n",
    "\n",
    " return d1_firing[0], d2_firing[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_spk_synchrony_index(data_dict_spk,start_time,end_time):\n",
    "    \n",
    "    syn_inx_d1 = []\n",
    "    syn_inx_d2 = []\n",
    "    start_ms = int(start_time * 1000)\n",
    "    end_ms = int(end_time * 1000)\n",
    "\n",
    "    for key, spike_times_list in data_dict_spk.items():\n",
    "        # Loop through each neuron's spike times\n",
    "        for spk_times in spike_times_list:\n",
    "            count_list = []\n",
    "            \n",
    "            # Calculate spike counts in 5 ms bins\n",
    "            for i in range(start_ms, end_ms, 5):\n",
    "                count = np.sum((spk_times > i) & (spk_times <= i + 5))\n",
    "                count_list.append(count)\n",
    "            \n",
    "            # Calculate the synchrony index as variance/mean of spike counts\n",
    "            # refer to Yim et al. 2011 Fano factor\n",
    "            mean_count = np.mean(count_list)\n",
    "            var_count = np.var(count_list)\n",
    "            synchrony_index = var_count / mean_count if mean_count > 0 else 0\n",
    "        \n",
    "            if key.split('_')[1] == 'd1':\n",
    "                syn_inx_d1.append(synchrony_index)\n",
    "            elif key.split('_')[1] == 'd2':\n",
    "                syn_inx_d2.append(synchrony_index)\n",
    "\n",
    "\n",
    "    return syn_inx_d1,syn_inx_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(data):    \n",
    "    mean = np.mean(data, axis=0)    \n",
    "    std_dev = np.std(data, axis=0)    \n",
    "    normalized_data = (data - mean) / std_dev    \n",
    "    return normalized_data\n",
    "\n",
    "def compute_synaptic_current(g_ex, v_m_ex, g_in, v_m_in, E_ex1, E_in1):\n",
    "    '''\n",
    "    Calculate synaptic currents (I_syn = g_syn * (V_m - E_syn))\n",
    "    '''\n",
    "    I_syn_ex = np.sum((v_m_ex - E_ex1) * g_ex)\n",
    "    I_syn_in = np.sum((v_m_in - E_in1) * g_in)\n",
    "    return I_syn_ex, I_syn_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_lfp(data_dict_lfp, start_time, end_time, E_ex1, E_in1):\n",
    "    start_ms = int(start_time  * 1000)\n",
    "    end_ms = int(end_time  * 1000)\n",
    "\n",
    "    start_idx = int((start_ms-1)*2000)#every 2000 slices is 1 ms \n",
    "    end_idx = int((end_ms-1)*2000)\n",
    "\n",
    "    LFP_list = []\n",
    "\n",
    "    for gex_d1, gin_d1, vm_d1, gex_d2, gin_d2, vm_d2 in zip(data_dict_lfp['d1_g_ex'], data_dict_lfp['d1_g_in'], \n",
    "                                                             data_dict_lfp['d1_V_m'], data_dict_lfp['d2_g_ex'], \n",
    "                                                             data_dict_lfp['d2_g_in'], data_dict_lfp['d2_V_m']):\n",
    "        Syn_d1_ex, Syn_d1_in, Syn_d2_ex, Syn_d2_in = [], [], [], []\n",
    "\n",
    "        for i in range(start_idx, end_idx, 2000):\n",
    "            I_syn_d1_ex, I_syn_d1_in = compute_synaptic_current(gex_d1[i-12000:i-10000], vm_d1[i-12000:i-10000], \n",
    "                                                                gin_d1[i:i+2000], vm_d1[i:i+2000], E_ex1, E_in1)\n",
    "            I_syn_d2_ex, I_syn_d2_in = compute_synaptic_current(gex_d2[i-12000:i-10000], vm_d2[i-12000:i-10000], \n",
    "                                                                gin_d2[i:i+2000], vm_d2[i:i+2000], E_ex1, E_in1)\n",
    "            Syn_d1_ex.append(I_syn_d1_ex)\n",
    "            Syn_d1_in.append(I_syn_d1_in)\n",
    "            Syn_d2_ex.append(I_syn_d2_ex)\n",
    "            Syn_d2_in.append(I_syn_d2_in)\n",
    "\n",
    "        # Calculate local field potential out of point neuron network\n",
    "        # refer to Mazzoni et al. 2015  reference weighted sum LFP proxy (RWS)\n",
    "        LFP_d1 = z_score_normalize(abs(np.array(Syn_d1_ex) - 1.65 * np.array(Syn_d1_in)))\n",
    "        LFP_d2 = z_score_normalize(abs(np.array(Syn_d2_ex) - 1.65 * np.array(Syn_d2_in)))\n",
    "\n",
    "        LFP_msn  = (LFP_d1+LFP_d2)/2\n",
    "\n",
    "        LFP_list.append(LFP_msn)\n",
    "\n",
    "    return LFP_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(data):\n",
    "    num_slices = len(data) // 21\n",
    "    slice_list=[]\n",
    "    for i in range(num_slices):\n",
    "        slice_list.append(data[i*21:(i+1)*21])\n",
    "    slice_list = np.array(slice_list)\n",
    "    slice_avg = np.mean(slice_list,axis=0)\n",
    "\n",
    "    return slice_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_dict_spk_ctl,data_dict_lfp_ctl \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mControl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(parms_set, output_dir)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Load the pickle file\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 29\u001b[0m     evs \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Process 'spk' data\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m category \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspk\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m subtype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md2\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dict_spk_ctl,data_dict_lfp_ctl = load_data('Control',output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_firing_ctl,d2_firing_ctl = proecess_data_spk_firing(data_dict_spk_ctl,start_time, end_time,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_ctl_d1, syn_ctl_d2 = process_data_spk_synchrony_index(data_dict_spk_ctl,start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_msn_ctl = process_data_lfp(data_dict_lfp_ctl, start_time, end_time, E_ex1=0, E_in1=-64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_ctl_d1_avg = avg_data(syn_ctl_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
